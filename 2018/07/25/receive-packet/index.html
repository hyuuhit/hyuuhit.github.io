<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hu yu's blog | Android | 服务端"><title>Linux kernel 链路层帧接收 | 属乌鸦的</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-129648993-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '85d80db9310fa34ab2f7d34beeff589b';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Linux kernel 链路层帧接收</h1><a id="logo" href="/.">属乌鸦的</a><p class="description">无知 &amp; 聒噪</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Linux kernel 链路层帧接收</h1><div class="post-meta">Jul 25, 2018</div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据结构"><span class="toc-number">1.</span> <span class="toc-text">数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#softnet-data"><span class="toc-number">1.1.</span> <span class="toc-text">softnet_data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#napi-struct"><span class="toc-number">1.2.</span> <span class="toc-text">napi_struct</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#packet-type"><span class="toc-number">1.3.</span> <span class="toc-text">packet_type</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#中断方式接收"><span class="toc-number">2.</span> <span class="toc-text">中断方式接收</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#中断部分"><span class="toc-number">2.1.</span> <span class="toc-text">中断部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#软中断部分"><span class="toc-number">2.2.</span> <span class="toc-text">软中断部分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NAPI方式接收"><span class="toc-number">3.</span> <span class="toc-text">NAPI方式接收</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#中断部分-1"><span class="toc-number">3.1.</span> <span class="toc-text">中断部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#软中断部分-1"><span class="toc-number">3.2.</span> <span class="toc-text">软中断部分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对比"><span class="toc-number">4.</span> <span class="toc-text">对比</span></a></li></ol></div></div><div class="post-content"><p>Linux kernel接收链路层帧时涉及中断部分、软中断部分，具体数据接收过程根据网卡驱动不同有传统的中断方式接收与NAPI方式接收，本文会分析两种方式的具体接收过程及两者的不同之处。</p>
<a id="more"></a>
<p>本文内容参考内核版本 3.10.0-862.el7.x86_64</p>
<p>ps：用词上不区分帧与数据包。</p>
<p><img src="http://blog-image.hyuuhit.com/2018/07/receive_packet.jpg" alt="链路层收包流程对比"></p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="softnet-data"><a href="#softnet-data" class="headerlink" title="softnet_data"></a>softnet_data</h3><p>网络数据包接收中一个重要变量是per-cpu变量的softnet_data，使用中简称为sd，其中统一了非napi驱动和napi驱动的处理逻辑。几个后文涉及的成员如下：</p>
<ul>
<li>input_pkt_queue<br>非napi设备ISR收包时将skb放入该队列，等待软中断处理。</li>
<li>backlog<br>为了统一两种处理方式，为所有非napi设备设计了一个napi_struct结构，与每个napi设备都有一个napi_struct结构共同在软中断的处理框架中生效。</li>
<li>process_queue<br>非napi设备在软中断中处理input_pkt_queue中数据包时，先先将skb链表转移挂载到这里。目的是尽快释放input_pkt_queue上的锁，这样同cpu上的ISR及其他cpu上的rps逻辑可以使用input_pkt_queue。</li>
<li>poll_list<br>链表挂载了所有在软中断中需要进一步处理的napi设备的napi_struct结构，同时非napi设备共用的backlog成员在需要处理数据包时也将挂载于此。</li>
</ul>
<figure class="highlight c"><figcaption><span>softnet_data</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Incoming packets are placed on per-cpu queues</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">softnet_data</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Qdisc</span>        *<span class="title">output_queue</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Qdisc</span>        **<span class="title">output_queue_tailp</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">poll_list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span>      *<span class="title">completion_queue</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff_head</span> <span class="title">process_queue</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* stats */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        processed;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        time_squeeze;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        cpu_collision;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        received_rps;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_RPS</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">softnet_data</span> *<span class="title">rps_ipi_list</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Elements below can be accessed between CPUs for RPS */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">call_single_data</span> <span class="title">csd</span> ____<span class="title">cacheline_aligned_in_smp</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">softnet_data</span> *<span class="title">rps_ipi_next</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        cpu;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        input_queue_head;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        input_queue_tail;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        dropped;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff_head</span> <span class="title">input_pkt_queue</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">napi_struct</span>  <span class="title">backlog</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="napi-struct"><a href="#napi-struct" class="headerlink" title="napi_struct"></a>napi_struct</h3><p>设备收包使用的结构体，这里看几个成员：</p>
<ul>
<li>poll_list<br>链表结构，用于挂载到sd-&gt;poll_list上。</li>
<li>poll<br>收包处理函数指针，软中断中调用以进行收包及数据包处理。</li>
<li>weight<br>权重，每次最多处理数据包数。</li>
</ul>
<figure class="highlight c"><figcaption><span>napi_struct</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Structure for NAPI scheduling similar to tasklet but with weighting</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">napi_struct</span> &#123;</span></span><br><span class="line">    <span class="comment">/* The poll_list must only be managed by the entity which</span></span><br><span class="line"><span class="comment">     * changes the state of the NAPI_STATE_SCHED bit.  This means</span></span><br><span class="line"><span class="comment">     * whoever atomically sets that bit can add this napi_struct</span></span><br><span class="line"><span class="comment">     * to the per-cpu poll_list, and whoever clears that bit</span></span><br><span class="line"><span class="comment">     * can remove from the list right before clearing the bit.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">poll_list</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span>       state;</span><br><span class="line">    <span class="keyword">int</span>         weight;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        gro_count;</span><br><span class="line">    <span class="keyword">int</span>         (*poll)(struct napi_struct *, <span class="keyword">int</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_NETPOLL</span></span><br><span class="line">    RH_KABI_DEPRECATE(<span class="keyword">spinlock_t</span>, poll_lock)</span><br><span class="line">        <span class="keyword">int</span>         poll_owner;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">net_device</span>   *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span>      *<span class="title">gro_list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span>      *<span class="title">skb</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">dev_list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">hlist_node</span>   <span class="title">napi_hash_node</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        napi_id;</span><br><span class="line">    RH_KABI_EXTEND(<span class="keyword">size_t</span>   size)</span><br><span class="line">    RH_KABI_EXTEND(struct hrtimer   timer)</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="packet-type"><a href="#packet-type" class="headerlink" title="packet_type"></a>packet_type</h3><p>数据包完成链路层处理后，需要提交给协议栈上层继续处理，每个<code>packet_type</code>结构就是数据包的一个可能去向。</p>
<ul>
<li>type<br>ETH_P_ALL或具体三层协议号，标记该<code>packet_type</code>收取什么类型的数据包，需要网络字节序。</li>
<li>dev<br>如果该<code>packet_type</code>只收取特定设备的数据包，则以该成员标识。</li>
<li>func<br>数据包后续真正的处理函数。比如IP协议的处理函数为<code>ip_rcv</code>。</li>
<li>id_match<br>看起来好像用来判断一个发出的数据包是否应该被该<code>packet_type</code>收取。因为这个函数指针使用的方式与<code>af_packet_priv == skb-&gt;sk</code>在一起且逻辑一致。</li>
<li>list<br>链表使用。</li>
</ul>
<figure class="highlight c"><figcaption><span>packet_type</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">packet_type</span> &#123;</span></span><br><span class="line">    __be16              type;   <span class="comment">/* This is really htons(ether_type). */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">net_device</span>   *<span class="title">dev</span>;</span>   <span class="comment">/* NULL is wildcarded here       */</span></span><br><span class="line">    <span class="keyword">int</span>                 (*func) (struct sk_buff *,</span><br><span class="line">                                 struct net_device *,</span><br><span class="line">                                 struct packet_type *,</span><br><span class="line">                                 struct net_device *);</span><br><span class="line">    <span class="keyword">bool</span>                (*id_match)(struct packet_type *ptype,</span><br><span class="line">                                 struct sock *sk);</span><br><span class="line">    <span class="keyword">void</span>                         *af_packet_priv;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">list</span>;</span></span><br><span class="line">    RH_KABI_RESERVE(<span class="number">1</span>)</span><br><span class="line">    RH_KABI_RESERVE(<span class="number">2</span>)</span><br><span class="line">    RH_KABI_RESERVE(<span class="number">3</span>)</span><br><span class="line">    RH_KABI_RESERVE(<span class="number">4</span>)</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>packet_type</code>结构体注册生效涉及两个全局变量和两个<code>net_device</code>结构内成员</p>
<ul>
<li><code>ptype_all</code><br>一个链表结构，注册了收取所有设备所有数据包的<code>packet_type</code>。</li>
<li><code>ptype_base</code><br>一个哈希表结构，每个槽位是一个链表，注册了收取所有设备特定协议数据包的<code>packet_type</code>。哈希结构用于通过协议号快速匹配。</li>
<li><code>dev-&gt;extended-&gt;ptype_all</code><br>一个链表结构，注册了只收取该设备所有数据包的<code>packet_type</code>。</li>
<li><code>dev-&gt;extended-&gt;ptype_specific</code><br>一个链表结构，注册了只收取该设备特定协议数据包的<code>packet_type</code>。</li>
</ul>
<figure class="highlight c"><figcaption><span>packet_type注册</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">```<span class="function"><span class="keyword">void</span> <span class="title">dev_add_pack</span><span class="params">(struct packet_type *pt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> *<span class="title">head</span> = <span class="title">ptype_head</span>(<span class="title">pt</span>);</span></span><br><span class="line"></span><br><span class="line">    spin_lock(&amp;ptype_lock);</span><br><span class="line">    list_add_rcu(&amp;pt-&gt;<span class="built_in">list</span>, head);</span><br><span class="line">    spin_unlock(&amp;ptype_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> struct list_head *<span class="title">ptype_head</span><span class="params">(<span class="keyword">const</span> struct packet_type *pt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (pt-&gt;type == htons(ETH_P_ALL))</span><br><span class="line">        <span class="keyword">return</span> pt-&gt;dev ? &amp;pt-&gt;dev-&gt;extended-&gt;ptype_all : &amp;ptype_all;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> pt-&gt;dev ? &amp;pt-&gt;dev-&gt;extended-&gt;ptype_specific :</span><br><span class="line">            &amp;ptype_base[ntohs(pt-&gt;type) &amp; PTYPE_HASH_MASK];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="中断方式接收"><a href="#中断方式接收" class="headerlink" title="中断方式接收"></a>中断方式接收</h2><p>这种方式的主要特征为，中断服务例程（ISR）中收取网卡数据填充sk_buff（后续称为skb）结构并放入内核内存，软中断中继续完成skb的处理并逐层递交上层协议栈处理。软中断处理过程中网卡中断始终开启。</p>
<p>中断方式接收数据是传统的Linux收包方式，这里参考3com的3c59x驱动介绍，文件为drivers/net/ethernet/3com/3c59x.c。</p>
<h3 id="中断部分"><a href="#中断部分" class="headerlink" title="中断部分"></a>中断部分</h3><ol>
<li>ISR为函数<code>vortex_interrupt</code>，这里会循环处理最多32个数据包，当有数据包需要接收时调用函数<code>vortex_rx</code>。</li>
<li><code>vortex_rx</code>中会配分一个skb（这个skb将会贯穿整个协议栈的处理过程），从设备读取数据写入skb（这里会区分dma方式与cpu读取方式），数据读取完毕后调用函数<code>eth_type_trans</code>确定三层协议并写入<code>skb-&gt;protocol</code>，对skb调用函数<code>netif_rx</code>（这是中断方式驱动接收数据进入内核处理代码的统一入口）。</li>
<li><code>netif_rx</code>是中断方式驱动程序接收数据进入内核处理的统一入口，是函数<code>netif_rx_internal</code>的一个包装。这里根据编译配置和运行配置区分为是否启用RPS（一种软件方式模拟多队列网卡RSS的技术，通过将不同flow的数据包分布到不同cpu进行后续处理的方式增强全局处理能力），如果启用了RPS将会选择一个cpu调用<code>enqueue_to_backlog</code>，如果未启用RPS将会对当前cpu调用<code>enqueue_to_backlog</code>。<code>enqueue_to_backlog</code>前后通过<code>get_cpu</code>和<code>put_cpu</code>确保内部处于抢占关闭状态（个人理解为，这个函数可能在中断上下文之外的环境中被调用，put_cpu是preempt_enable的宏定义，在内核可抢占配置下preempt_enable内部隐含了可能的抢占调度，这可以使数据包入队列后尽快启动软中断处理过程，在可能的情况下尽快处理数据包。可抢占调度的前提为需要调度标记处于开启状态、preempt_count为0、中断处于关闭状态）</li>
<li><code>enqueue_to_backlog</code><ul>
<li>首先关闭了中断（这里很好理解，因为这个函数后续操作的数据结构可能被其他的ISR访问，为了避免冲突必须关闭中断。因为关闭中断的情况下是不会发生抢占调度的，因此印证了前文中的put_cpu是为了尽快启动软中断这一目的。）</li>
<li>如果配置了RPS，将会上spinlock对临界区进行保护，避免其他cpu的并发冲突。如果没有配置RPS则没有spinlock操作，因为操作临界区资源是per-cpu变量，关闭中断的情况下当前cpu不会有其他代码操作临界区资源。</li>
<li>如果per-cpu类型softnet_data变量sd中input_pkt_queue队列空，则将非napi设备共用的napi_struct结构sd-&gt;backlog的status设置为<code>NAPI_STATE_SCHED</code>然后挂载到sd-&gt;poll_list上并将当前cpu的软中断NET_RX_SOFTIRQ置于激活状态，这样当后续处理中软中断可以执行时将继续处理数据包。然后将skb放入sd-&gt;input_pkt_queue末尾。如果input_pkt_queue不为空，说明软中断NET_RX_SOFTIRQ之前已经激活过并等待运行，不需要再额外激活，而且backlog已经挂载到poll_list，直接将skb放入input_pkt_queue末尾既可。</li>
<li>开启之前关闭的中断。</li>
</ul>
</li>
</ol>
<p>这里运行结束后，收包中断的上半部已经完成，input_pkt_queue中的skb后续将在下半部软中断中继续处理。</p>
<h3 id="软中断部分"><a href="#软中断部分" class="headerlink" title="软中断部分"></a>软中断部分</h3><p><code>net_rx_action</code>是<code>NET_RX_SOFTIRQ</code>软中断处理函数，这个函数逻辑如下：</p>
<ol>
<li>将<code>sd-&gt;poll_list</code>上挂载的<code>napi_struct</code>全部取下保存到局部变量<code>list</code>中。由于这步操作的是per-cpu变量，而且可能与ISR操作冲突，因此需要处于中断关闭环境。</li>
<li>依次对<code>list</code>每个<code>napi_struct</code>结构调用函数<code>napi_poll</code>，参数传入局部变量<code>repoll</code>地址，用于当数据包未全部处理时标记后续需要继续处理。直到全部处理完毕或处理超过300个数据包或执行超过2个时钟滴答（如果HZ为1000，也就是2毫秒）。<ul>
<li>将<code>napi_struct</code>结构从链表中摘除。如果有配置netpoll且设备启用了netpoll的话，还需要持续尝试当前cpu获取napi-&gt;poll_owner，以避免与其他cpu上netpoll的冲突。</li>
<li>检查status是否为NAPI_STATE_SCHED而后调用<code>napi_struct</code>结构的<code>poll</code>函数指针完成对数据的操作。前文说过，非napi设备共用<code>sd-&gt;backlog</code>这个<code>napi_struct</code>，napi设备每个驱动有自己的<code>napi_struct</code>，生效位置就是这里。</li>
<li>如果poll返回已经处理的数据包数小于提供的配额，说明已经没有数据包需要处理，不需要后续挂载到repoll了，因此直接返回。</li>
<li>判断是否disable了，并做相应处理。</li>
<li>判断网卡驱动是否已经将该<code>napi_struct</code>重新挂载到某链表上（有些驱动会自主调用napi_schedule，这是不应该的），如果已经挂载则printk警告信息，后续不做其他操作。</li>
<li>如果进行到了最后说明poll函数指针运行消耗了所有的配额，可能仍有数据包未处理完成，因此这里将其重新挂载到repoll链表上等待后续再次激活。</li>
</ul>
</li>
<li>将<code>list</code>、<code>repoll</code>、<code>sd-&gt;poll_list</code>上挂载的<code>napi_struct</code>依次重新挂载到<code>sd-&gt;poll_list</code>上，这个顺序表明下次软中断中需要处理的网络设备顺序分别是本次未来得及处理的、本次未处理完全的、新增的。如果<code>sd-&gt;poll_list</code>非空将会标记NET_RX_SOFTIRQ为激活等待再次执行。这部分操作同样需要处于中断关闭环境。</li>
</ol>
<p><code>process_backlog</code>是<code>sd-&gt;backlog-&gt;poll</code>函数指针指向的函数，在<code>net_dev_init</code>中初始化。这里有一些对配额的调整逻辑不做赘述，主要逻辑为：</p>
<ol>
<li>将<code>sd-&gt;input_pkt_queue</code>中链接的数据包转移挂载到<code>sd-&gt;process_queue</code>上。这一步的目的应该是在rps环境下可以尽快释放<code>input_pkt_queue</code>的锁，这样其他cpu才可能根据rps将数据包放入该队列。</li>
<li>循环处理<code>process_queue</code>上的每个skb，直到队列为空或处理数据包数达到配额。处理函数为<code>__netif_receive_skb</code>。</li>
<li>返回处理的数据包数。</li>
</ol>
<p><code>__netif_receive_skb</code>是函数<code>__netif_receive_skb_core</code>的一个包装，<code>__netif_receive_skb_core</code>中完成了对skb真正的处理及提交上层协议栈。</p>
<ol>
<li>保存<code>skb-&gt;dev</code>到局部变量<code>orig</code>，因为后续这个dev可能发生变化。保存收包设备索引。如果是vlan包，脱掉vlan头。</li>
<li>遍历全局变量链表<code>ptype_all</code>，对链接的每个<code>packet_type</code>结构调用函数<code>deliver_skb</code><br>这一步与下一步一同构成了将skb提交到taps嗅探设备，比如libpcap使用的PF_PACKET。<br>ps：skb成员pfmemalloc标记会引发跳过对<code>ptype_all</code>的处理。</li>
<li>遍历<code>skb-&gt;dev-&gt;extended-&gt;ptype_all</code>，对链接的每个<code>packet_type</code>结构调用函数<code>deliver_skb</code><br>这一步与上一步一同构成了将skb提交到taps嗅探设备，比如libpcap使用的PF_PACKET。区别在于这里的是只嗅探特定net_device的。<br>s：skb成员pfmemalloc标记同样会引发跳过此步骤。</li>
<li>有一段对<code>skb-&gt;dev-&gt;rx_handler</code>的处理，好像是与虚拟网络设备相关，这部分先跳过。</li>
<li>遍历<code>ptype_base</code>上特定的哈希槽，对匹配协议号的<code>packet_type</code>结构调用函数<code>deliver_skb</code><br>这一步与下一步一同构成了将skb提交到上层协议栈。这一步有一个判断条件与之前的rx_handler有关，暂时不关心。</li>
<li>遍历<code>orig_dev-&gt;extended-&gt;ptype_specific</code>，对匹配协议号的<code>packet_type</code>结构调用函数<code>deliver_skb</code><br>这一步与上一步一同构成了将skb提交到上层协议栈。区别在于这里的是只对特定net_device有效的协议栈。</li>
<li>如果到这里skb成员dev发生了变更，遍历<code>skb-&gt;dev-&gt;extended-&gt;ptype_specific</code>，对匹配协议号的<code>packet_type</code>结构调用函数<code>deliver_skb</code></li>
</ol>
<p>上文的<code>deliver_skb</code>内部实际增加了skb的引用计数，然后调用<code>packet_type</code>成员<code>func</code>函数指针将skb提交到上层协议栈，对skb的释放操作将由<code>func</code>指向的函数具体负责。另外对<code>func</code>的调用每次都是延迟处理，最后一次调用甚至抛开了<code>deliver_skb</code>直接调用<code>func</code>，个人理解为由于最后<code>__netif_receive_skb_core</code>不再持有skb了，因此引用计数可以直接传递给最后一次调用的<code>func</code>，这样也就省去了一次<code>kfree_skb</code>的函数调用。这里贴一下IP协议的<code>packet_type</code>，可以看到IP协议数据包的处理函数是<code>ip_rcv</code>。到这里链路层部分已经完成了，但是软中断工作并没有完成，软中断中将继续进行上层协议栈的处理。</p>
<figure class="highlight c"><figcaption><span>IP协议packet_type的注册位置是函数inet_init</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">packet_type</span> <span class="title">ip_packet_type</span> __<span class="title">read_mostly</span> = &#123;</span></span><br><span class="line">    .type = cpu_to_be16(ETH_P_IP),</span><br><span class="line">    .func = ip_rcv,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="NAPI方式接收"><a href="#NAPI方式接收" class="headerlink" title="NAPI方式接收"></a>NAPI方式接收</h2><p>NAPI既New API，这种方式的主要特征为，ISR中只将需要接收数据的网卡放入一个特定的待接收列表中，并标记需要在软中断中接收网卡数据，所有的数据接收及协议栈上的逐层处理都在软中断中完成。ISR中会关闭网卡中断，直到软中断处理了该网卡所有数据后才会将该网卡中断开启。</p>
<p>NAPI方式接收数据是较新一些的Linux收包方式，这里参考intel的e100驱动介绍，文件为drivers/net/ethernet/intel/e100.c。</p>
<h3 id="中断部分-1"><a href="#中断部分-1" class="headerlink" title="中断部分"></a>中断部分</h3><p>ISR为函数<code>e100_intr</code>，逻辑如下：</p>
<ol>
<li>检查该网卡是否可以调度由当前cpu接收数据包，如果不可以将不会进行后续步骤。（可以调度的话，会将<code>napi_struct</code>的status设置为<code>NAPIF_STATE_SCHED</code>。）</li>
<li>关闭该网卡中断。</li>
<li>将该网卡的<code>napi_struct</code>结构挂载到per-cpu变量<code>sd-&gt;poll_list</code>上，将当前cpu软中断NET_RX_SOFTIRQ标记为激活等待执行。</li>
</ol>
<p>到这里中断部分就处理完成了，而且该网卡的中断后续将处于关闭状态。</p>
<h3 id="软中断部分-1"><a href="#软中断部分-1" class="headerlink" title="软中断部分"></a>软中断部分</h3><p>软中断入口的开始部分与非NAPI方式完全相同，只是<code>napi_struct</code>结构的<code>poll</code>函数指针不同，e100驱动的<code>poll</code>函数指针指向为函数<code>e100_poll</code></p>
<p>收包函数<code>e100_rx_clean</code>内部在填充skb后调用的函数栈为<code>netif_receive_skb</code>-&gt;<code>netif_receive_skb_internal</code>-&gt;<code>__netif_receive_skb</code>，这里就是上文描述过的了。</p>
<p>最后处理的工作量如果小于配额，说明已经全部处理完，这时调用<code>napi_complete</code>处理该结构，并重新开启该网卡中断。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">e100_poll</span><span class="params">(struct napi_struct *napi, <span class="keyword">int</span> budget)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">nic</span> *<span class="title">nic</span> = <span class="title">container_of</span>(<span class="title">napi</span>, <span class="title">struct</span> <span class="title">nic</span>, <span class="title">napi</span>);</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> work_done = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    e100_rx_clean(nic, &amp;work_done, budget);</span><br><span class="line">    e100_tx_clean(nic);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If budget not fully consumed, exit the polling mode */</span></span><br><span class="line">    <span class="keyword">if</span> (work_done &lt; budget) &#123;</span><br><span class="line">        napi_complete(napi);</span><br><span class="line">        e100_enable_irq(nic);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> work_done;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>NAPI方式在数据包量较大时可以降低中断数量。设想一个场景，有大量小包到来，如果是非NAPI设备将会有大量的中断产生，中断是可以打断软中断执行的，cpu时间大量占用在中断处理上，此时软中断中数据包真正的处理无法进行。NAPI在大量数据包到来时使用poll轮询的方式收取数据包使cpu可以更有效的处理数据包。</p>
<p>但是可以看到3c59x驱动中每次中断也设定了可以收取多个数据包，在一定程度上也可以减少中断的数量。</p>
</div><div class="tags"><a href="/tags/linux/">linux</a></div><div class="post-nav"><a class="pre" href="/2018/08/03/linux-kernel-thread/">Linux kernel thread 内核线程</a><a class="next" href="/2018/07/15/netfilter/">Netfilter 内核数据包过滤框架</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://www.hyuuhit.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/libvirt/">libvirt</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/suricata/">suricata</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/vmware/" style="font-size: 15px;">vmware</a> <a href="/tags/数据结构/" style="font-size: 15px;">数据结构</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/04/11/rcu-usage/">RCU 使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/16/tc-tbf-qdisc/">tc tbf qdisc</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/08/function-call-stack/">gdb查看寄存器及内存数据与函数调用栈分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/16/libpcap-cutoff-captured-packet/">libpcap在libvirt虚拟化环境下捕获数据包不完整的一种情况分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/27/bash-audit/">一种简单的bash审计方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/20/bash-invocation/">bash 调用方式与配置文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/17/uriparser/">uriparser 解析处理URI</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/06/noblock-rabbitmq-c/">rabbitmq-c 非阻塞订阅</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/20/libyaml/">libyaml 解析配置文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/23/netns/">Linux network namespace 简单解读</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">属乌鸦的.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>